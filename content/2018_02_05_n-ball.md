---
title: On the Ball in $n$ Euclidean Dimensions
shorttitle: On the Ball in n Euclidean Dimensions
date: 6 February 2018
category: math
tags: calculus, proof, long
slug: n-ball
---

One of my favourite formulas in mathematics is the one for the area of a circle, $\pi r^2$.
Its simplicity intrigued my young mind; the circle is, in a sense, the simplest, the *roundest* shape, and this formula seems to encapsulate the circle's aura of "completion."
As I grew older, I learned more such formulas for the volumes and surface areas of familiar geometric objects.
In particular, I learned of the formula for the volume of a sphere $\frac{4}{3}\pi r^3$.
Amused as I was by these clever formulas, my curiosity began to take hold of me.
Questions filled my mind: isn't it interesting, that as the dimension of the round shape went from 2 to 3, so did the exponent on the radius?
Where did the $\frac{4}{3}$ come from?
Why do the formulas stop after circle and sphere?
What comes next?
Does anything come next?
These questions lay dormant in my mind for a while, until my friend [Arif Aulakh](https://github.com/arifaulakh) challenged me to find an expression for the volume of a sphere in an arbitrary number of dimensions.
My curiosity rekindled, I set out, in search of the higher-dimensional sphere, to answer the question: what comes next?

# Introduction

Before we embark on our journey, we need to lay out some basic definitions.
A sphere is the set of all points a given distance (let's call it $R$) from a given center point.
A ball is the space whose boundary is a sphere, or the set of all points whose distance from a given center point is less than or equal to $R$.
For example, a sphere in $2$ dimensions is called a circle, and the corresponding ball is called a disk.
Upon hearing the word "circle," you might imagine a flat coin-like object.
That's not what a mathematician means when they say circle.
To a mathematician, a circle is just the boundary of that coin, while a disk is the entirety of the points contained in (and on the boundary of) the coin.
Similarly, a sphere is the bounding surface of a ball.
So let's call a ball in $n$ Euclidean dimensions with a certain radius the $n$-ball of radius $R$.
Also, note that a $1$-ball is just a line segment.
In $2$ dimensions, we say closed figures have area, and in $3$ dimensions, we say they have volume.
The arbitrary-dimensional analogue of this concept is "content."
For example, the 2-ball has content $\pi R^2$, the 3-ball $\frac{4}{3}\pi R^2$.
We shall find a general formula for the content of an $n$-ball of radius $R$.
Along the way, we will uncover and explore some interesting related results.

# A Recurrence Relation

Intutively, we can construct a $3$-ball out of a bunch of thin disks (think of slicing a tomato).
In the same way, we can construct a disk out of a bunch of thin line segments.
And remember, a disk is a $2$-ball, and a line segment is a $1$-ball.
There seems to be a certain modularity to the $n$-dimensional ball.
Let's formalize this idea on the scale of $2$ dimensions and then generalize to an arbitrary number of dimensions.

We wish to construct a $2$-ball from the interval $[-R,R]$, centered on $0$.
Let the distance from $0$ of a point on this interval be $r$.
Then construct a $1$-ball (line segment) of radius $\sqrt{R^2 - r^2}$ centered on and perpendicular to the interval.
Doing this for all points on the interval yields a $2$-ball, constructed from the sum of infinitely many $1$-balls.
Similarly, we can construct a $3$-ball from infinitely many $2$-balls centered on and perpendicular to the interval $[-R,R]$.

Generalizing to $n$ dimensions yields the recurrence relation
\begin{equation}
	V_{n}(R) = \int_{-R}^{R} V_{n-1}\left(\sqrt{R^2 - r^2}\right) \d r.
	\label{first-recurrence}
\end{equation}
Uniformly scaling any object in $n$ dimensions by $R$ increases the content of that object by a factor of $R^n$.
This result can be shown with linear algebra.
We shall prove a weaker version of this statement for the $n$-ball.

> **Lemma 1. (Proportionality)**
Uniformly scaling a $n$-dimensional ball by $R$ increases the content of the ball by $R^n$.

As a base case, proportionality clearly holds for $n = 0$, where all balls have content $1$.
Here scaling by a factor of $R$ scales content by a factor of $R^0 = 1$.
Then assume inductively that proportionality holds for an $(n-1)$-ball.
Then we can factor $R^{n-1}$ from the integrand in \eqref{first-recurrence}:
\begin{equation}
	V_{n}(R) = R^{n-1}\int_{-R}^{R} V_{n-1}\left(\sqrt{1 - \left(\frac{r}{R}\right)^2}\right) \d r.
\end{equation}
Substituting $x = \frac{r}{R}, \d x = \frac{\d x}{R}$ yields
\begin{equation}
	V_n(R) = R^n\int_{-1}^1 V_{n-1}\left(\sqrt{1-x^2}\right) \d x = R^nV_n(1),
	\label{induction-2}
\end{equation}
which proves that proportionality holds in $n$ dimensions and, by induction, in all non-negative integer dimensions.
$\qed$

Then proportionality transforms \eqref{induction-2} into
\begin{equation}
	\begin{split}
		V_{n}(R) &= R^nV_{n-1}(1)\int_{-1}^{1} \left(\sqrt{1-x^2}\right)^{n-1} \d x \\
		&= V_{n-1}(R)R \int_{-1}^{1} \left(1-x^2\right)^\frac{n-1}{2} \d x.
	\end{split}
\end{equation}
Because the integrand is an even function in $x$,
\begin{equation}
	V_{n}(R) = 2V_{n-1}(R)R \int_{0}^{1} \left(1-x^2\right)^\frac{n-1}{2} \d x.
\end{equation}
The expression of interest to us is the integral.
For notational simplicity, we define
\begin{equation}
	I_{k} = 2\int_{0}^{1} \left(1-x^2\right)^\frac{k}{2} \d x.
	\label{I-initial}
\end{equation}
Then
\begin{equation}
	V_{n}(R) = I_{n-1}V_{n-1}(R)R.
	\label{volume-recurrence}
\end{equation}
Let us now solve for $I_{n-1}$.

# Solving the Integral

We shall prove the result
\begin{equation}
	I_{n-1} = \frac{\sqrt{\pi}\Gamma\left(\frac{n+1}{2}\right)}{\Gamma(\frac{n}{2}+1)}
	\label{I-final}
\end{equation}
in two ways: analytically and with a probabalistic argument.

## An Analytical Argument
We substitute $x = \cos\theta, \d x = -\sin\theta\d\theta$ into \eqref{I-initial}.
\begin{equation}
	\begin{split}
		I_{n-1} &= -2\int_{\frac{\pi}{2}}^0 \left(1-\cos^2\theta\right)^\frac{n-1}{2} \sin\theta \d\theta \\
		&= 2\int_0^{\frac{\pi}{2}} \left(\sqrt{\sin^2\theta}\right)^{n-1} \sin\theta \d\theta \\
		&= 2\int_0^{\frac{\pi}{2}} |\sin\theta|^{n-1} \sin\theta \d\theta.
	\end{split}
\end{equation}
Because $\sin\theta$ is non-negative over $[0,\frac{\pi}{2}]$, we have
\begin{equation}
	I_{n-1} = 2\int_0^{\frac{\pi}{2}} \sin^n\theta \d\theta.
\end{equation}
We define the function
\begin{equation}
	\I(n,m) = 2\int_0^{\frac{\pi}{2}} \sin^n\theta \cos^m\theta \d\theta.
	\label{I-definition}
\end{equation}
Then $I_{n-1} = \I(n,0)$.
We substitute $t = \tan^2\theta, \d t = 2\tan\theta\sec^2\theta \d\theta = 2\sin\theta\sec^3\theta\d\theta$ into \eqref{I-definition}.
This gives $\frac{1}{1+t} = \cos^2\theta$ and $1 - \frac{1}{1+t} = \frac{t}{1+t} = \sin^2\theta$.
\begin{equation}
	\begin{split}
		\I(n,m) &= 2\int_0^{\frac{\pi}{2}} (\sin^2\theta)^\frac{n}{2} (\cos^2\theta)^\frac{m}{2} \d\theta \\
		&= \int_0^{\frac{\pi}{2}} (\sin^2\theta)^{\frac{n-1}{2}} (\cos^2\theta)^{\frac{m+3}{2}} 2\sin\theta\sec^3\theta \d\theta \\
		&= \int_0^{\infty} \left(\frac{t}{1+t}\right)^{\frac{n-1}{2}} \left(\frac{1}{1+t}\right)^{\frac{m+3}{2}} \d t \\
		&= \int_0^{\infty} \frac{t^{\frac{n-1}{2}}}{(1+t)^{\frac{n+m}{2}+1}} \d t.
	\end{split}
\end{equation}
For simplicity, let $n = 2\alpha - 1, m = 2\beta - 1$.
Then
\begin{equation}
	\I(n,m) = \int_0^{\infty} \frac{t^{\frac{n-1}{2}}}{(1+t)^{\frac{n+m}{2}+1}} \d t = \int_0^{\infty} \frac{t^{\alpha-1}}{(1+t)^{\alpha + \beta}} \d t.
	\label{alpha-beta}
\end{equation}

Let us now state two lemmas which we shall prove later.

> **Lemma 2.**
Given real numbers $\alpha, \beta$, we have
\begin{equation}
	\int_0^{\infty} \frac{t^{\alpha-1}}{(1+t)^{\alpha + \beta}} \d t = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}.
	\label{claim}
\end{equation}

> **Lemma 3.**
\begin{equation}
	\Gamma\left(\frac{1}{2}\right) = \sqrt{\pi}
\end{equation}

Applying Lemma 2 to \eqref{alpha-beta} gives
\begin{equation}
	\I(n,m) = \frac{\Gamma\left(\frac{n+1}{2}\right)\Gamma\left(\frac{m+1}{2}\right)}{\Gamma\left(\frac{n+m}{2} + 1\right)}.
	\label{I-gamma}
\end{equation}
Recall that $I_{n-1} = \I(n,0)$.
Then applying Lemma 3 gives
\begin{equation}
	\begin{split}
		I_{n-1} &= \frac{\Gamma\left(\frac{n+1}{2}\right)\Gamma\left(\frac{1}{2}\right)}{\Gamma(\frac{n}{2}+1)} \\
		&= \frac{\sqrt{\pi}\Gamma\left(\frac{n+1}{2}\right)}{\Gamma(\frac{n}{2}+1)},
	\end{split}
\end{equation}
which establishes \eqref{I-final}.
$\qed$

## A Statistical Argument
Let ``choosing a number'' be done with a uniform probability.
Let $\alpha$ and $\beta$ be positive integers.
The probability of choosing first choosing a real $p$ in the interval $[0,1]$, then choosing $\alpha$ real numbers in $[0,p]$, and then choosing $\beta$ real numbers in $[p,1]$ is $\int_0^1 p^\alpha(1-p)^\beta \d p$.
Then the probability of choosing $\alpha + \beta + 1$ real numbers in $[0,1]$ such that the first number is $p$, some $\alpha$ of the remaining numbers are in $[0,p]$, and some $\beta$ of them are in $[p,1]$ is $\binom{\alpha + \beta}{\alpha}\int_0^1 p^\alpha(1-p)^\beta$.
But this is the same as the probability that, after $p$ and $\alpha + \beta$ real numbers in $[0,1]$ are placed in increasing order, $p$ happens to be in the $(\alpha + 1)$-th position, or $\frac{1}{\alpha + \beta + 1}$.
This yields
\begin{equation}
	\begin{split}
		\binom{\alpha + \beta}{\alpha} \int_0^1 p^\alpha(1-p)^\beta \d p &= \frac{1}{\alpha + \beta + 1} \\
		\frac{(\alpha + \beta)!}{\alpha!\beta!}\int_0^1 p^\alpha(1-p)^\beta \d p &= \frac{1}{\alpha + \beta + 1} \\
		\int_0^1 p^\alpha(1-p)^\beta \d p &= \frac{\alpha!\beta!}{(\alpha + \beta + 1)!}.
	\end{split}
\end{equation}
Generalizing with the gamma function $\Gamma(n+1) = n!$, we have
\begin{equation}
	\int_0^1 p^\alpha(1-p)^\beta \d p = \frac{\Gamma(\alpha + 1)\Gamma(\beta + 1)}{\Gamma(\alpha + \beta + 2)}.
\end{equation}
Substituting $p = x^2, \d p = 2x\d x$ yields
\begin{equation}
	2\int_0^1 x^{2\alpha+1}(1-x^2)^\beta \d x = \frac{\Gamma(\alpha + 1)\Gamma(\beta + 1)}{\Gamma(\alpha + \beta + 2)}
\end{equation}
Setting $\alpha = -\frac{1}{2}, \beta = \frac{n-1}{2}$ yields the desired \eqref{I-final}:
\begin{equation}
	\begin{split}
		2\int_0^1 (1-x^2)^\frac{n-1}{2} \d x &= \frac{\Gamma\left(\frac{1}{2}\right)\Gamma(\frac{n+1}{2})}{\Gamma(\frac{n}{2}+1)} \\
		I_{n-1} &= \frac{\sqrt{\pi}\Gamma(\frac{n+1}{2})}{\Gamma(\frac{n}{2}+1)}.
	\end{split}
\end{equation}
$\qed$

# A General Formula
Now let's put it all together.

> **Theorem 1.** The content of an $n$-ball of radius $R$, denoted $V_n(R)$, is given by
\begin{equation}
	V_n(R) = \frac{R^n\pi^\frac{n}{2}}{\Gamma\left(\frac{n}{2}+1\right)}.
	\label{general-volume}
\end{equation}

Expanding \eqref{volume-recurrence} using \eqref{I-final}, we have
\begin{equation}
	\begin{split}
		V_n(R) &= I_{n-1}V_{n-1}(R)R \\
		&= R\frac{\sqrt{\pi}\Gamma\left(\frac{n+1}{2}\right)}{\Gamma\left(\frac{n}{2}+1\right)}V_{n-1}(R) \\
		&= \left(R\frac{\sqrt{\pi}\Gamma\left(\frac{n+1}{2}\right)}{\Gamma\left(\frac{n}{2}+1\right)}\right)\left(R\frac{\sqrt{\pi}\Gamma\left(\frac{n}{2}\right)}{\Gamma\left(\frac{n-1}{2}+1\right)}\right)\cdots\left(R\frac{\sqrt{\pi}\Gamma\left(\frac{n+2-m}{2}\right)}{\Gamma\left(\frac{n-m}{2}+1\right)}\right)V_{n-m}(R) \\
		&= R^m\pi^\frac{m}{2}\left(\frac{\Gamma\left(\frac{n-1}{2}+1\right)}{\Gamma\left(\frac{n}{2}+1\right)}\right)\left(\frac{\Gamma\left(\frac{n-2}{2} + 1\right)}{\Gamma\left(\frac{n-1}{2}+1\right)}\right)\cdots\left(\frac{\Gamma\left(\frac{n-m}{2} + 1\right)}{\Gamma\left(\frac{n-m+1}{2}+1\right)}\right)V_{n-m}(R).
	\end{split}
\end{equation}
The $m$-th numerator is the same as the $(m+1)$-st denominator, so
\begin{equation}
	V_n(R) = V_{n-m}(R)R^m\pi^{\frac{m}{2}}\frac{\Gamma\left(\frac{n-m}{2} + 1\right)}{\Gamma\left(\frac{n}{2}+1\right)}.
\end{equation}
Because a $0$-dimensional ball of any radius consists of only one point, $V_0(R) = 1$.
Setting $m = n$, we obtain our general expression for the content of an $n$-dimensional ball and establish Theorem 1.

# Proofs and Other Results

## A Trigonometric Integral Identity
From \eqref{I-gamma}, it follows that $\I(n,m) = \I(m,n)$.
So $\frac{1}{2}\I(n,0) = \frac{1}{2}\I(0,n)$.
Then \eqref{I-definition} implies the interesting identity
\begin{equation}
	\int_0^{\frac{\pi}{2}} \sin^n\theta \d\theta = \int_0^{\frac{\pi}{2}} \cos^n\theta \d\theta.
\end{equation}

## Identities Involving the Gamma Function

### Gamma Fraction Identity: Proof of Lemma 2

Lemma 2, which states that
\begin{equation}
	\int_0^{\infty} \frac{t^{\alpha-1}}{(1+t)^{\alpha + \beta}} \d t = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)},
\end{equation}
was key in our analytical argument.
We shall prove it here.

The gamma function is defined as
\begin{equation}
	\Gamma(z) = \int_0^\infty e^{-t}t^{z-1} \d t.
	\label{gamma}
\end{equation}
In \eqref{gamma} we make the substitution $t = pq$, $\d t = q\d p$.
\begin{equation}
	\begin{split}
		\Gamma(\alpha) &= \int_0^\infty e^{-pq}(pq)^{\alpha-1} q\d p \\
		&= \int_0^\infty q^\alpha e^{-pq}p^{\alpha-1} \d p.
	\end{split}
	\label{gamma-reworked}
\end{equation}
We multiply both sides of \eqref{gamma-reworked} by $\Gamma(\beta) = \int_0^\infty e^{-q}q^{\beta-1} \d q$.
\begin{equation}
	\begin{split}
		\Gamma(\alpha)\Gamma(\beta) &= \left(\int_0^\infty q^\alpha e^{-pq}p^{\alpha-1} \d p\right)\left(\int_0^\infty e^{-q}q^{\beta-1} \d q\right) \\
		&= \int_0^\infty \int_0^\infty e^{-q-pq}q^{\alpha+\beta-1}p^{\alpha-1} \d p \d q \\
		&= \int_0^\infty p^{\alpha-1} \d p \int_0^\infty e^{-q(1+p)}q^{\alpha+\beta-1} \d q.
	\end{split}
	\label{gamma-product}
\end{equation}
In the inner integral we substitute $q = \frac{s}{1+p}, \d q = \frac{\d s}{1 + p}$.
Then
\begin{equation}
	\begin{split}
		\int_0^\infty e^{-q(1+p)}q^{\alpha+\beta-1} \d q &= \int_0^\infty e^{-s}\left(\frac{s}{1+p}\right)^{\alpha+\beta-1} \frac{\d s}{1+p} \\
		&= \frac{1}{(1+p)^{\alpha+\beta}}\int_0^\infty e^{-s}s^{\alpha+\beta-1} \d s \\
		&= \frac{\Gamma(\alpha+\beta)}{(1+p)^{\alpha+\beta}}.
	\end{split}
	\label{g-prod-reworked}
\end{equation}
Substituting \eqref{g-prod-reworked} into \eqref{gamma-product}, we have
\begin{equation}
	\begin{split}
		\Gamma(\alpha)\Gamma(\beta) &= \int_0^\infty p^{\alpha-1} \frac{\Gamma(\alpha+\beta)}{(1+p)^{\alpha+\beta}} \d p \\
		\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)} &= \int_0^\infty \frac{p^{\alpha-1}}{(1+p)^{\alpha+\beta}} \d p,
	\end{split}
\end{equation}
which establishes the desired result.
$\qed$

### Gamma of One-Half: Proof of Lemma 3

We shall prove Lemma 3, that $\Gamma\left(\frac{1}{2}\right) = \sqrt{\pi}$.
In \eqref{claim}, set $\alpha = \beta = \frac{1}{2}$.
Then
\begin{equation}
	\begin{split}
		\frac{\Gamma\left(\frac{1}{2}\right)\Gamma\left(\frac{1}{2}\right)}{\Gamma(1)} &= \int_0^\infty \frac{t^{-\frac{1}{2}}}{1+t} \d t \\
		\Gamma^2\left(\frac{1}{2}\right) &= \int_0^\infty \frac{1}{\sqrt{t}(1+t)} \d t.
	\end{split}
\end{equation}
We substitute $t = x^2, \d t = 2x\d x = 2\sqrt{t}\d x$:
\begin{equation}
	\begin{split}
		\Gamma^2\left(\frac{1}{2}\right) &= 2\int_0^\infty \frac{1}{1 + x^2} \d x \\
		&= 2\left(\arctan x \big|_0^\infty \right) \\
		&= 2\cdot\frac{\pi}{2} \\
		&= \pi,
	\end{split}
\end{equation}
so
\begin{equation}
	\Gamma\left(\frac{1}{2}\right) = \pm\sqrt{\pi}.
\end{equation}
But in the integral representation of $\Gamma(z)$, the integrand $e^{t}t^{z-1}$ is positive if $z > 0$.
This yields the desired result,
\begin{equation}
	\Gamma\left(\frac{1}{2}\right) = \sqrt{\pi}
\end{equation}
A consequence of this result is the value of the famous Gaussian integral
\begin{equation}
	\int_{-\infty}^\infty e^{-x^2} \d x,
\end{equation}
whose integrand has no elementary antiderivative.
Substituting $t = x^2, \d t = 2t^{\frac{1}{2}}\d x$ into the integral representation of $\Gamma\left(\frac{1}{2}\right)$, we have
\begin{equation}
	\begin{split}
		\sqrt{\pi} &= \Gamma\left(\frac{1}{2}\right) \\
		&= \int_0^\infty e^{-t}t^{-\frac{1}{2}} \d t \\
		&= 2\int_0^\infty e^{-x^2} \d x.
	\end{split}
\end{equation}
Because the integrand $e^{-x^2}$ is an even function, it follows that
\begin{equation}
	\int_{-\infty}^\infty e^{-x^2} \d x = \sqrt{\pi}.
\end{equation}

### Gamma Function Doubling Formula

We have the following result.
> **Theorem 2. (Gamma Function Doubling Formula)**
\begin{equation}
	\Gamma(2z) = \frac{2^{2z-1}\Gamma(z)\Gamma\left(z + \frac{1}{2}\right)}{\sqrt{\pi}}
	\label{gamma-duplication}
\end{equation}

To prove this result, we shall use integration by parts and \eqref{I-final}.
Let
\begin{equation}
	A_k = \int_{0}^{1} \left(1-x^2\right)^k \d x.
	\label{A-definition}
\end{equation}
Then, integrating by parts, we have
\begin{equation}
	\begin{split}
		A_k &= x(1-x^2)^k \big|_0^1 - \int_0^1 -2xk(1-x^2)^{k-1}x \d x \\
		&= 2k\int_0^1 x^2(1-x^2)^{k-1} \d x \\
		&= 2k\int_0^1 (1-(1-x^2))(1-x^2)^{k-1} \d x \\
		&= 2k\int_0^1 (1-x^2)^{k-1} - (1-x^2)^k \d x \\
		&= 2kA_{k-1} - 2kA_k \\
		&= \frac{2k}{2k+1}A_{k-1}.
	\end{split}
\end{equation}
Expanding the recurrence relation yields
\begin{equation}
	A_k = \frac{(2k)(2k-2)\cdots4\cdot2}{(2k+1)(2k-1)\cdots3\cdot1}.
\end{equation}
Let us first deal with the numerator.
We know that
\begin{equation}
	k! = k(k-1)\cdots2\cdot1.
\end{equation}
Multiplying each of the $k$ terms on the right-hand side by $2$ yields the numerator.
So the numerator is equal to $2^kk!$.
Then we deal with the denominator.
We know that
\begin{equation}
	(2k+1)! = (2k+1)(2k)\cdots2\cdot1.
\end{equation}
Dividing both sides of this equation by $2^kk!$ yields the denominator.
So the denominator is equal to $\frac{(2k+1)!}{2^kk!}$.
Then
\begin{equation}
	\begin{split}
		A_k &= \frac{2^kk!}{\frac{(2k+1)}{2^kk!}} \\
		&= \frac{(2^kk!)^2}{(2k+1)!}.
	\end{split}
\end{equation}
Generalising using the gamma function $\Gamma(n+1) = n!$ yields
\begin{equation}
	A_k = \frac{2^{2k}\Gamma^2(k+1)}{\Gamma(2k+2)}.
	\label{A-gamma}
\end{equation}
From \eqref{I-initial} and \eqref{A-definition}, $I_{n-1} = 2A_{\frac{n-1}{2}}$, so by \eqref{A-gamma},
\begin{equation}
	I_{n-1} = \frac{2^n\Gamma^2\left(\frac{n+1}{2}\right)}{\Gamma(n+1)}.
	\label{I-by-parts}
\end{equation}
Equating \eqref{I-by-parts} with \eqref{I-final} and making the substitution $z = \frac{n+1}{2}$ establishes Theorem 2.
\begin{equation}
	\begin{split}
		\frac{2^{2z-1}\Gamma^2(z)}{\Gamma(2z)} &= \frac{\sqrt{\pi}\Gamma(z)}{\Gamma(z + \frac{1}{2})} \\
		\Gamma(2z) &= \frac{2^{2z-1}\Gamma(z)\Gamma\left(z + \frac{1}{2}\right)}{\sqrt{\pi}}.
	\end{split}
\end{equation}
$\qed$

This result is very powerful.
It implies that, combined with the recurrence relation $\Gamma(n+1) = n\Gamma(n)$, we can compute $\Gamma(\frac{n}{2})$ for any positive integer $n$. 
Then we can also compute all expressions of the form $\Gamma(\frac{n}{4})$, because the right-hand side of \eqref{gamma-duplication} will be in terms of expressions of the form $\Gamma(\frac{n}{2})$.
Thus for any positive real number $r$ whose binary expansion is finite---that is, for any positive rational $r$---we can thus compute $\Gamma(r)$.
And because every irrational number can be written as the limit of the partial sums of a sequence of rational numbers, we can compute $\Gamma(r)$ for any positive real $r$.

### Approximating the Logarithmic Derivative of the Gamma Function
Consider the logarithmic derivative of the gamma function, which we shall call $\mathscr{G}(x)$:
\begin{equation}
	\mathscr{G}(x) = \frac{\d}{\d x}\ln\Gamma(x) = \frac{\Gamma'(x)}{\Gamma(x)}.
	\label{log-deriv-gamma}
\end{equation}
For the sake of this section, let $\mathscr{G} = \frac{\Gamma'(x)}{\Gamma(x)}$.
Then we shall prove

> **Theorem 3.**
The following upper and lower bounds hold for the logarithmic derivative of the gamma function:
\begin{equation}
	\ln x - \frac{1}{x} < \mathscr{G}(x) < \ln x.
	\label{gamma-log-deriv-bounds}
\end{equation}

To do this, we first show the following lemma, which may seem intuitive.

> **Lemma 4.**
Let $f(x)$ be a differentiable function defined on $[a,b]$.
Then if $f'(x) > 0$ for all $x \in [a,b]$, then $f(x)$ is strictly increasing.

By the Fundamental Theorem of Calculus,
\begin{equation}
	\int_a^b f'(x) \d x = f(b) - f(a).
\end{equation}
If $f'(x) > 0$ for all $x$, then because the integral of a positive integrand is also positive, $f(b) > f(a)$ for all $x$.
That is, $f(x)$ is strictly increasing.
$\qed$

We also use the following lemma for continuous functions, which is a special case of the Cauchy-Schwarz inequality.

> **Lemma 5.**
Let $f$ and $g$ be continuous functions defined over $[a,b]$.
Then we have
\begin{equation}
	\left(\int_a^b fg \d t\right)^2 \le \left(\int_a^b f^2 \d t\right)\left(\int_a^b g^2 \d t\right).
\end{equation}
In particular, equality holds if and only if $f$ is proportional to $g$; that is, there exists some $z$ such that for all $x \in [a,b]$, we have $zf(x) = g(x)$.

Let's take some contant $z$.
Then $0 \le (fz - g)^2$.
And because the integral of a non-negative function is also non-negative, for all real $z$, we have
\begin{equation}
	0 \le \int_a^b (fz - g)^2 \d t = \left(\int_a^b f^2 \d t \right)z^2 - \left(\int_a^b 2fg \d t\right)z + \left(\int_a^b g^2 \d t\right).
\end{equation}
Because this quadratic is non-negative, its discriminant must be non-positive, such that
\begin{equation}
	4\left(\int_a^b fg \d t\right)^2 \le 4\left(\int_a^b f^2 \d t\right)\left(\int_a^b g^2 \d t\right).
	\label{discriminant}
\end{equation}
Equality only holds in \eqref{discriminant} if $\int_a^b (fz - g)^2 \d t = 0$.
Consider a function $h'$ continuous over $[a,b]$ such that $\int_a^b h'(x) \d x = 0$.
By the Fundamental Theorem of Calculus, this integral equals $h(b) - h(a)$, so $h(a) = h(b)$; that is, $h$ is a constant function, so the integrand $h'$ is the zero function.
Thus equality only holds in \eqref{discriminant} if $fz = g$.
$\qed$

> **Lemma 6.**
For non-negative real $x$, $\mathscr{G}(x)$ is a strictly increasing function.

We will prove Lemma 6 by showing that $\mathscr{G}'(x)$ is positive everywhere.
We have
\begin{equation}
	\begin{split}
		\Gamma'(x) &= \frac{\d}{\d x}\int_0^\infty e^{-t}t^{x-1} \d t \\
		&= \int_0^\infty \frac{\partial}{\partial x}\, e^{-t}t^{x-1} \d t \\
		&= \int_0^\infty e^{-t}t^{x-1}\ln t \d t,
	\end{split}
\end{equation}
and, similarly,
\begin{equation}
	\Gamma''(x) = \int_0^\infty e^{-t}t^{x-1} \ln^2 t \d t.
\end{equation}
Furthermore,
\begin{equation}
	\mathscr{G}'(x) = \frac{\Gamma(x)\Gamma''(x)-(\Gamma'(x))^2}{\Gamma^2(x)}.
	\label{gamma-second-deriv}
\end{equation}
Substituting $\alpha = \sqrt{e^{-t}t^{x-1}}$ and $\beta = \ln t\sqrt{e^{-t}t^{x-1}}$ into \eqref{gamma-second-deriv} yields
\begin{equation}
	\mathscr{G}'(x) = \frac{\left(\int_0^\infty \alpha^2 \d t\right) \left(\int_0^\infty \beta^2 \d t\right) - \left(\int_0^\infty \alpha\beta \d t\right)^2}{\Gamma^2(x)}.
	\label{integral-gamma-2-deriv}
\end{equation}
We note that functions $\alpha$ and $\beta$ are continuous and not proportional (because $\ln t$ is not constant with respect to $t$) to one another over $[0,\infty)$.
Then Lemma 5 shows, with strict inequality, that
\begin{equation}
	\left(\int_0^\infty \alpha\beta \d t\right)^2 < \left(\int_0^\infty \alpha^2 \d t\right) \left(\int_0^\infty \beta^2 \d t\right).
	\label{fg-inequality}
\end{equation}
The denominator of \eqref{integral-gamma-2-deriv} is always positive, so \eqref{fg-inequality} shows that \eqref{gamma-second-deriv} is positive for all non-negative real $x$.
Finally, Lemma 4 establishes that $\mathscr{G}(x)$ is a strictly increasing function.
$\qed$

> **Lemma 7.**
We have $\mathscr{G}(x + 1) = \mathscr{G}(x) + \frac{1}{x}$.

We have $\Gamma(x+1) = x\Gamma(x)$, so $\ln(\Gamma(x+1)) = \ln\Gamma(x) + \ln x$.
Differentiating establishes the result.
$\qed$

> **Lemma 8.**
We have the following inequality: $\mathscr{G}(x) < \ln x < \mathscr{G}(x + 1)$.

By the Mean Value Theorem, there exists some $z$ in $(x, x+1)$ such that
\begin{equation}
	\begin{split}
		\mathscr{G}(z) &= \frac{\ln\Gamma(x+1) - \ln\Gamma(x)}{x+1-x} \\
		&= \ln(x\Gamma(x)) - \ln\Gamma(x) \\
		&= \ln x.
	\end{split}
\end{equation}
In particular, note that $x < z < x + 1$.
By Lemma 6, $\mathscr{G}(x)$ is strictly increasing.
So $\mathscr{G}(x) < \mathscr{G}(z) = \ln x < \mathscr{G}(x+1)$, and we establish Lemma 8.
$\qed$

Finally, we can establish Theorem 3 by applying Lemma 7 and Lemma 8:
\begin{equation}
	\begin{split}
		\mathscr{G}(x) < \ln x < \mathscr{G}(x + 1) &= \mathscr{G}(x) + \frac{1}{x} \\
		\ln x < \mathscr{G}(x + 1) &< \ln x + \frac{1}{x} \\
		\ln x - \frac{1}{x} < \mathscr{G}(x) &< \ln x.
	\end{split}
\end{equation}
$\qed$

## Surface Area of Arbitrary Dimensional Spheres
We can build a the $2$-ball, or disk, from the union of concentric $2$-sphere (circle) shells all evenly spaced by a distance $\d r$.
This is like the layers of an onion.
This generalizes to $n$ dimensions, where an $n$-ball is the union of concentric $n$-sphere shells.
As $\d r$ tends to $0$, we find that the content of a $n$-ball is the sum of the surface areas of the infinitely many $n$-spheres with radii ranging from $0$ to $R$.
That is,
\begin{equation}
	V_n(R) = \int_0^R S_n(r) \d r,
\end{equation}
which gives
\begin{equation}
	S_n(R) = \frac{\d V_n(R)}{\d R}.
\end{equation}
Substituting \eqref{general-volume} yields
\begin{equation}
	\begin{split}
		S_n(R) &= \frac{nR^{n-1}\pi^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}+1\right)} \\
		&= \frac{nR^{n-1}\pi^{\frac{n}{2}}}{\frac{n}{2}\Gamma\left(\frac{n}{2}\right)} \\
		&= \frac{2R^{n-1}\pi^\frac{n}{2}}{\Gamma\left(\frac{n}{2}\right)}.
	\end{split}
\end{equation}

## Implications of the Content of Balls of Arbitrary Dimension

### Small Dimensions

| $n$ | $V$                      |$\approx V$|
|-----|--------------------------|-----------|
| $0$ | $1$                      | $1$       |
| $1$ | $2R$                     | $2R$      |
| $2$ | $\pi{}R^2$               | $3.14R^2$ |
| $3$ | $\frac{4}{3}\pi{}R^3$    | $4.19R^3$ |
| $4$ | $\frac{\pi^2}{2}R^4$     | $4.94R^4$ |
| $5$ | $\frac{8\pi^2}{15}R^5$   | $5.26R^5$ |
| $6$ | $\frac{\pi^3}{6}R^6$     | $5.17R^6$ |
| $7$ | $\frac{16\pi^3}{105}R^7$ | $4.73R^7$ |
| $8$ | $\frac{\pi^4}{24}R^8$    | $4.06R^8$ |

![The dimensionless content of the unit ball in $n$ dimensions. Note the global maximum, after which the content quickly decreases.](http://gautammanohar.com/figures/n-ball-graph.png){width = 50% }

We shall ignore the "unit" of content and instead compare contents as dimenionless quantities.
The integer dimension that maximizes the content of the unit ball is evidently $n = 5$.
The figure reveals that this maximum is actually at $n \approx 5.26$.
In fact, the global maximum of the function $n\mapsto \frac{R^n\pi^\frac{n}{2}}{\Gamma\left(\frac{n}{2}+1\right)}, n \ge 0$ depends on $R$ and is given by
\begin{equation}
	\begin{split}
		\frac{\d}{\d n}\left(\frac{R^n\pi^\frac{n}{2}}{\Gamma\left(\frac{n}{2}+1\right)}\right) &= 0\\
		\frac{\Gamma\left(\frac{n}{2}+1\right)(R\sqrt{\pi})^n\ln(R\sqrt{\pi}) - \frac{1}{2}(R\sqrt{\pi})^n\Gamma'\left(\frac{n}{2}+1\right)}{\Gamma^2\left(\frac{n}{2}+1\right)} &= 0 \\
		\Gamma\left(\frac{n}{2}+1\right)\ln(R\sqrt{\pi}) - \frac{1}{2}\Gamma'\left(\frac{n}{2}+1\right) &= 0 \\
		\ln(\pi R^2) &= \frac{\Gamma'\left(\frac{n}{2}+1\right)}{\Gamma\left(\frac{n}{2}+1\right)}.
	\end{split}
\end{equation}
This equation cannot be solved for $n$ analytically, so we approximate.
From Theorem 3, we have
\begin{equation}
	\ln n < \frac{\Gamma'(n+1)}{\Gamma(n+1)} < \ln n + \frac{1}{n},
\end{equation}
which means that the maximal content of a ball of radius $R$ is attained in
\begin{equation}
	\begin{split}
		\ln\left(\frac{n}{2}\right) &\sim \ln(\pi R^2) \\
		n &\sim 2\pi R^2. 
	\end{split}
\end{equation}

### Large Dimensions
For a given radius $R$, the content of an $n$-ball goes to 0 as $n$ goes to infinity.
That is,
\begin{equation}
	\lim_{n\to\infty} \frac{R^n\pi^\frac{n}{2}}{\Gamma\left(\frac{n}{2}+1\right)} = 0.
\end{equation}
In fact, this result holds for any expression of the form $\frac{a^n}{\Gamma(kn + 1)} = \frac{a^n}{(kn)!}$ for positive real $a$ and $k$.
Define the function $f(n) = \frac{a^n}{(kn)!}$.
Consider the limiting ratio $\frac{f(n+1)}{f(n)}$:
\begin{equation}
	\begin{split}
		\lim_{n\to\infty} \frac{\frac{a^{n+1}}{(k(n+1))!}}{\frac{a^n}{(kn)!}} &= \lim_{n\to\infty} \frac{a^{n+1}(kn)!}{a^n(kn+k)!} \\
		&= \lim_{n\to\infty} \frac{a}{(kn + 1)(kn + 2)\cdots(kn + k)} \\
		&= 0.
	\end{split}
\end{equation}
Then by the ratio test, the series $\sum_{n=0}^\infty \frac{a^n}{(kn)!}$ converges because its limiting ratio is 0.
Because the terms of a convergent series must tend to 0, $\frac{a^n}{(kn)!}$ tends to 0.
Thus we have proven that for a given $R$, $V_n(R)$ tends to $0$ as $n$ increases).

# Conclusion
Our most important result was a general expression for the content of an $n$-ball of radius $R$:
\begin{equation}
	V_n(R) = \frac{R^n\pi^\frac{n}{2}}{\Gamma(\frac{n}{2}+1)}.
\end{equation}
We also derived two useful identities related to the gamma function:
\begin{equation}
	\Gamma(2z) = \frac{2^{2z-1}\Gamma(z)\Gamma\left(z + \frac{1}{2}\right)}{\sqrt{\pi}}
\end{equation}
and
\begin{equation}
	\ln x - \frac{1}{x} < \frac{\Gamma'(x)}{\Gamma(x)} < \ln x.
\end{equation}
Our next steps would be to examine the properties of other geometric figures in $n$ Euclidean dimensions, such as hypercubes and simplices.
We could also analyze balls in non-Euclidean spaces, such as hyperbolic space.